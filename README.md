Driver Sleep Detection
This project leverages multiple machine learning models to predict whether drivers are sleeping or awake based on various features from a dataset sourced from Kaggle(https://www.kaggle.com/datasets/naddamuhhamed/sleepy-driver-eeg-brainwave-data/data). The goal is to improve road safety by detecting the state of drivers and taking preventive measures to avoid accidents.

Project Overview
Driver fatigue is a significant cause of road accidents, and this project aims to address this issue using machine learning. By analyzing features in the dataset, such as driver behavior and physiological data, the model predicts whether a driver is asleep or awake.

The following machine learning models were used in this project:

Logistic Regression
Random Forest
Support Vector Machine (SVM)
Decision Tree
K-Nearest Neighbors (KNN)
Gradient Boosting
Key Features
Binary classification: The project classifies drivers into two categories: asleep or awake.
Multiple ML models: Six different machine learning models were built and compared for performance.
Dataset from Kaggle: The dataset contains features relevant to driver behavior and state.
Dataset
The dataset, sourced from Kaggle(https://www.kaggle.com/datasets/naddamuhhamed/sleepy-driver-eeg-brainwave-data/data), contains various features to determine the state of drivers. These features could include physiological signals like eye movement, heart rate, steering patterns, or other behavioral data. The target variable in the dataset indicates whether the driver is asleep or awake.

Features: Various physiological and behavioral indicators.
Target: A binary label indicating whether the driver is asleep or awake.
Dataset Source:
The dataset was sourced from Kaggle (https://www.kaggle.com/datasets/naddamuhhamed/sleepy-driver-eeg-brainwave-data/data).
Models Used
Logistic Regression: A simple, linear model for binary classification.
Random Forest: An ensemble model that builds multiple decision trees and aggregates their results.
Support Vector Machine (SVM): A classifier that uses hyperplanes to separate data.
Decision Tree: A tree-based algorithm that splits data into branches based on feature values.
K-Nearest Neighbors (KNN): A non-parametric method that classifies data based on the closest data points.
Gradient Boosting: An ensemble model that builds models sequentially, improving the prediction step by step.
